{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6730f-5d76-450b-9788-ec883d024f57",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers å¾®è°ƒè®­ç»ƒå…¥é—¨\n",
    "\n",
    "æœ¬ç¤ºä¾‹å°†ä»‹ç»åŸºäº Transformers å®ç°æ¨¡å‹å¾®è°ƒè®­ç»ƒçš„ä¸»è¦æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- æ•°æ®é›†ä¸‹è½½\n",
    "- æ•°æ®é¢„å¤„ç†\n",
    "- è®­ç»ƒè¶…å‚æ•°é…ç½®\n",
    "- è®­ç»ƒè¯„ä¼°æŒ‡æ ‡è®¾ç½®\n",
    "- è®­ç»ƒå™¨åŸºæœ¬ä»‹ç»\n",
    "- å®æˆ˜è®­ç»ƒ\n",
    "- æ¨¡å‹ä¿å­˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
   "metadata": {},
   "source": [
    "## YelpReviewFull æ•°æ®é›†\n",
    "\n",
    "**Hugging Face æ•°æ®é›†ï¼š[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
    "\n",
    "### æ•°æ®é›†æ‘˜è¦\n",
    "\n",
    "Yelpè¯„è®ºæ•°æ®é›†åŒ…æ‹¬æ¥è‡ªYelpçš„è¯„è®ºã€‚å®ƒæ˜¯ä»Yelp Dataset Challenge 2015æ•°æ®ä¸­æå–çš„ã€‚\n",
    "\n",
    "### æ”¯æŒçš„ä»»åŠ¡å’Œæ’è¡Œæ¦œ\n",
    "æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†ç±»ï¼šè¯¥æ•°æ®é›†ä¸»è¦ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼šç»™å®šæ–‡æœ¬ï¼Œé¢„æµ‹æƒ…æ„Ÿã€‚\n",
    "\n",
    "### è¯­è¨€\n",
    "è¿™äº›è¯„è®ºä¸»è¦ä»¥è‹±è¯­ç¼–å†™ã€‚\n",
    "\n",
    "### æ•°æ®é›†ç»“æ„\n",
    "\n",
    "#### æ•°æ®å®ä¾‹\n",
    "ä¸€ä¸ªå…¸å‹çš„æ•°æ®ç‚¹åŒ…æ‹¬æ–‡æœ¬å’Œç›¸åº”çš„æ ‡ç­¾ã€‚\n",
    "\n",
    "æ¥è‡ªYelpReviewFullæµ‹è¯•é›†çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "```json\n",
    "{\n",
    "    'label': 0,\n",
    "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
    "}\n",
    "```\n",
    "\n",
    "#### æ•°æ®å­—æ®µ\n",
    "\n",
    "- 'text': è¯„è®ºæ–‡æœ¬ä½¿ç”¨åŒå¼•å·ï¼ˆ\"ï¼‰è½¬ä¹‰ï¼Œä»»ä½•å†…éƒ¨åŒå¼•å·éƒ½é€šè¿‡2ä¸ªåŒå¼•å·ï¼ˆ\"\"ï¼‰è½¬ä¹‰ã€‚æ¢è¡Œç¬¦ä½¿ç”¨åæ–œæ åè·Ÿä¸€ä¸ª \"n\" å­—ç¬¦è½¬ä¹‰ï¼Œå³ \"\\n\"ã€‚\n",
    "- 'label': å¯¹åº”äºè¯„è®ºçš„åˆ†æ•°ï¼ˆä»‹äº1å’Œ5ä¹‹é—´ï¼‰ã€‚\n",
    "\n",
    "#### æ•°æ®æ‹†åˆ†\n",
    "\n",
    "Yelpè¯„è®ºå®Œæ•´æ˜Ÿçº§æ•°æ®é›†æ˜¯é€šè¿‡éšæœºé€‰å–æ¯ä¸ª1åˆ°5æ˜Ÿè¯„è®ºçš„130,000ä¸ªè®­ç»ƒæ ·æœ¬å’Œ10,000ä¸ªæµ‹è¯•æ ·æœ¬æ„å»ºçš„ã€‚æ€»å…±æœ‰650,000ä¸ªè®­ç»ƒæ ·æœ¬å’Œ50,000ä¸ªæµ‹è¯•æ ·æœ¬ã€‚\n",
    "\n",
    "## ä¸‹è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22fac7f2-3491-4484-b745-d7193bccc10b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T09:32:28.224328Z",
     "iopub.status.busy": "2024-07-16T09:32:28.223916Z",
     "iopub.status.idle": "2024-07-16T09:32:28.236334Z",
     "shell.execute_reply": "2024-07-16T09:32:28.235508Z",
     "shell.execute_reply.started": "2024-07-16T09:32:28.224296Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:08.688130Z",
     "iopub.status.busy": "2024-07-16T04:54:08.687729Z",
     "iopub.status.idle": "2024-07-16T04:54:25.128818Z",
     "shell.execute_reply": "2024-07-16T04:54:25.128237Z",
     "shell.execute_reply.started": "2024-07-16T04:54:08.688107Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#ä¸‹è½½æ•°æ®é›† æ•°æ®é›†çš„åç§°ä¸ºyelp_review_full\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.130060Z",
     "iopub.status.busy": "2024-07-16T04:54:25.129775Z",
     "iopub.status.idle": "2024-07-16T04:54:25.136444Z",
     "shell.execute_reply": "2024-07-16T04:54:25.135962Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.130037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#æ•°æ®é›†åŒ…å«2ä¸ªç‰¹å¾ label å’Œ text . train 650000æ¡ test 50000æ¡\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.137396Z",
     "iopub.status.busy": "2024-07-16T04:54:25.137177Z",
     "iopub.status.idle": "2024-07-16T04:54:25.141818Z",
     "shell.execute_reply": "2024-07-16T04:54:25.141065Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.137375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.144459Z",
     "iopub.status.busy": "2024-07-16T04:54:25.143077Z",
     "iopub.status.idle": "2024-07-16T04:54:25.152460Z",
     "shell.execute_reply": "2024-07-16T04:54:25.151695Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.144431Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.154708Z",
     "iopub.status.busy": "2024-07-16T04:54:25.154339Z",
     "iopub.status.idle": "2024-07-16T04:54:25.159439Z",
     "shell.execute_reply": "2024-07-16T04:54:25.158987Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.154684Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af560b6-7d21-499e-9b82-114be371a98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.160472Z",
     "iopub.status.busy": "2024-07-16T04:54:25.160272Z",
     "iopub.status.idle": "2024-07-16T04:54:25.171760Z",
     "shell.execute_reply": "2024-07-16T04:54:25.171343Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.160452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Went in to see a friend to stand up comedy.\\n\\nBartender was friendly but they lacked certain spirits like Jack Daniels honey or Wild Turkey honey and the bartender only knew how to make drinks only containing two ingredients.  Not as \\\"up to date\\\" as I would have liked to see.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Found this place on the Triple D site and had to go. We were staying on the strip so took a cab. There is a little sign above a black door with a door bell button on the right. Don't need to buzz just walk in.\\nWe weren't sure we were at the right place when we walked in but the staff was friendly and assured us we were. Pretty typical dive bar atmosphere, the owner is from Buffalo so there was a ton of Buffalo stuff on the walls which was nice as that is the area we are from. We ordered two wee's to split between four of us: \\n\\nThe Ginuea: This was featured on the show so we tried it. Fantastic!! The sauce was what put it over the top for me.\\n\\nThe Margarita: I was a little disappointed in the lack of sauce and basil(I was just expecting/wanted more) but every one thought it was good.\\n\\nWe finished with the fried dough: powdered sugar, chocolate sauce and fried=mmmmm.\\n\\nWe inquired about getting a cab to get back to the strip and the waitress called one up for us. I told her I would include her name and I forgot it (I'm very sorry!) but she was great. If I go back to Vegas I'll definitely go back. Even with the bar bill and tip it was cheaper than anywhere else we ate and as good or better.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Unsure weather to give this place 2 or 3 stars. \\nJust go back after staying here for 5 nights. Had a room on the 10th floor which had an OK view of the strip, but a little low for the Belligio show, but room was comped, so who am I to argue. \\nDecent sized room, a nice bathroom ( I like bathrooms with separate showers) and nice counter space. \\nNow the bad. Shower had a low flow head which sucked, plus it was unadjustable so you couldn't move the spray away from you. The blow dryer had so much lint in it that it barely blew any air. The shampoo at all Harrahs properties is watery just not good. The TV is an old crt with very limited number of channels to choose from. But worst thing of all, as reviewer DL stated, both my wife and I had weird bite marks on out lower legs at the end of the trip. I pulled back the sheets and looked closely for bugs, but didn't see any.( I don't know how tiny bedbugs are) Just seem like a strange coincidence with the DL story. \\nAside from the room, it has a nice selection of restaurants, a decent casino, and is centrally located on the strip so you can go over to Caesars or Belliago without too much effort.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>We were going out on a very busy night, and decided to go to our local Streets location for dinner.  The service was excellent.  They introduced a new item on the menu - the Broasted Chicken.  My husband and I are both big fans of good, fresh fried chicken, and we're really not into KFC - so we decided to give this a try - and we've been back 4 times for the chicken since!  It's crispy on the outside, very lightly coated, and juicy on the inside - and not greasy!  It's pressure cooked, so you don't have the grease of typical fried chicken.  We've invited friends there and they raved about it as well.  Give Streets of New York at Ray and Kyrene a chance - the chicken is what you'll be back for, time and again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 star</td>\n",
       "      <td>DO NOT PATRONIZE THIS SHOP!!\\n\\nI drive a Dodge Charger and I have been having some trouble with a shimmy in my steering wheel.  The first time I went in, I had them balance all 4 tires.  I was very wary because when I was waiting for them to write up the service order, the attendant didn't know how to ring in the service.  When he asked his associate, that second guy told him to write it up at a lower price than the guy I was talking to quoted me.  When I asked, he gave me some excuse that right now I don't even remember.  It wasn't too big of a difference, but I still remember feeling a little ripped off because of course I was made to pay the higher price.  \\n\\nThe real problem happened when I returned a couple weeks later to get an alignment as the balancing did not fix the problem.  All seemed to be going well until I was about to be picked up by my girlfriend.  The mechanic who was going to test drive the car backed out of the parking spot I was in.  She was pulling into the parking lot at the same time coming down the aisle.  The mechanic proceeded to hammer the gas pedal, squealing the tires and almost hitting my girlfriend head on as he maneuvered around her and out of the parking lot.  Needless to say I was furious and confronted the manager.  He assured me that it would be handled.  \\n\\nWhen we were leaving, the mechanic pulled into the parking lot making an ILLEGAL left turn into the parking lot which was blocked by a median.  Instead of going to the nearest light and making a safe and legal u-turn, he decided to make the left heading up the wrong side of the road.  I was livid at this point.  I approached the mechanic in my car and his response was that he did not squeal the tires and that he makes that turn all the time basically asking me what the big deal was.  The manager came up to me giving me his best effort to rectify the situation by promising me a free oil change on my next visit.  REALLY?!?!?!? I told him that I perform my own oil changes and just to fix my car.\\n\\nWhen I went back to pick up my car, the manager continued to assure me that everything would be taken care of and offered apologies.  He gave me his best effort I guess, but his resolution was to charge me full price for the awful experience I had just gone through and to give me a free oil change on my next visit which will NEVER happen even after I told him that I change my own oil.  \\n\\nWell, my shimmy problem is still not fixed,  which there might be something wrong with the rotors, still haven't figured that out.  I don't hold the continued problem against them, they performed the work I asked them to do, but of course there was no diagnosis of the actual problem or extra effort.  Kinda feels like I just got a hardly satisfying haircut at Super Clips or something.  Their only concern is getting cars in and out of the shop, not developing lifelong customers.  I received no comfort by the actions of their mechanic while driving my car.  If I saw him peel out in my car, almost hit my girlfriend, and perform an illegal left turn in the 5 seconds I saw him driving my car, what kind of driving maneuvers is he doing while he's out of sight and what other corners is he cutting while performing work on my car?\\n\\nI will never be going back to this shop or any other Tire Works shops for any service even if it is given to me for free.  AWFUL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Love this theater! It's clean, great service, popcorn hot &amp; perfect. Perfect date night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Still one of my favorites.  Don't waste your time at any other spa on the strip.  I have yet to find one that surpasses this, and I've tried most.\\n\\nMake sure you save time to enjoy the variety of baths.  I could fall asleep in that room on the chairs for hours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>I was stressed out at the beginning of my wait at the airport and all I wanted was a Bloody Mary. Luckily I hatched that thought right outside of Home Turf Sports Bar which advertised \\\"mile high bloody mary's\\\". As I walked in I found it to be messy and confusing. It's really unclear as to whether you should sit down and be waited on or go to the bar and order. This fact is exacerbated by the fact that they have a standing room only bar 5 feet from the bar they serve alcohol at which makes it hard to tell if there's a line or just people chilling. \\n  Aside from that I got a double Bloody Mary for 10 bucks, not too bad for an airport, but it definitely wasn't a mile high or anything that should be boasting awesomeness. I could have made just as good of one at home. Honestly. That being said... I was glad to have my drink and a place to rest my hat for a bit. Definitely 3 star worthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>It wasn't busy at all when I went in. The hostess was nice and got me right to a seat. These servers here are quick. Soon as I picked up my menu the girl was asking what drink I wanted. I asked her to come back seeing that they have a lot of chocolate drinks, and I wanted some extra calories today. \\n\\nSo the prices turned me off about those good yummy sounding drinks, and I just got a coke, which was pricey  $2.25 for a diet coke sucks. \\nI didn't want to spend too much, and It looked like I had no choice. I had a lot of good choices to eat. The menu items sounded so good, and I went with the Really Crunchy Mac n Cheese. \\n\\nI drank my coke quickly, and they asked me several times if I needed a refill but I really actually was worried that they would charge me an extra $2.25 for it, so I said no. \\n\\nThe meal was ok.. I mean it was good don't get me wrong, but not the best I tried. Soon half way in the meal I bite on some seasoning, they had in the mac and cheese, and I hated it. I have tasted this before in another meal once, and I don't know what it is! I changed my mind as I was eating it and instend of ok..it was now bad because of that one little seasoning. I just stopped eating and hurried to check the menu for a drink, they could get the taste out of my mouth because it makes me sick to my stomach. \\n\\nI got a cookie shake to go that cost $7.75.\\nThat was the best part of this whole meal was that shake! It was soo good! It had white chocolate cream and Oreo cookies! I would come back just for that shake! \\n\\nI think this place was decent. I just picked the wrong meal for me.  If I come back, I will try something with less ingredients. \\n\\nMy whole meal was about $25.00, and that's not including the tip, and that was just for one individual. If you arrive with friends and family, you know where the price will be.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 star</td>\n",
       "      <td>It's always fun to see new restaurants open in the Burgh.  Not so much this one.  I was there with a friend, both of us really hungry.  We ordered soup that took an hour to be served. When we \\\"reminded\\\" our server we were told they were swamped.  I counted 12 other people.  I asked for no onions on my chili, but it was covered in onions.  Maybe it was to hide the taste.  I ordered catfish which I couldn't eat.  I saw two other people send their food back.  My soft drink glass was never refilled.  The bill for 2 people was over $50.  That was for soup and an entree'.  When we left the hostess was busy chatting on her cell phone.  This is a miss.  Much better places to eat in the Waterfront.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
   "metadata": {},
   "source": [
    "## é¢„å¤„ç†æ•°æ®\n",
    "\n",
    "ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°åï¼Œä½¿ç”¨ Tokenizer æ¥å¤„ç†æ–‡æœ¬ï¼Œå¯¹äºé•¿åº¦ä¸ç­‰çš„è¾“å…¥æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¡«å……ï¼ˆpaddingï¼‰å’Œæˆªæ–­ï¼ˆtruncationï¼‰ç­–ç•¥æ¥å¤„ç†ã€‚\n",
    "\n",
    "Datasets çš„ `map` æ–¹æ³•ï¼Œæ”¯æŒä¸€æ¬¡æ€§åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨é¢„å¤„ç†å‡½æ•°ã€‚\n",
    "\n",
    "ä¸‹é¢ä½¿ç”¨å¡«å……åˆ°æœ€å¤§é•¿åº¦çš„ç­–ç•¥ï¼Œå¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:25.172656Z",
     "iopub.status.busy": "2024-07-16T04:54:25.172449Z",
     "iopub.status.idle": "2024-07-16T04:54:26.849763Z",
     "shell.execute_reply": "2024-07-16T04:54:26.848860Z",
     "shell.execute_reply.started": "2024-07-16T04:54:25.172635Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "#ä½¿ç”¨çš„æ˜¯bert-base-casedæ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# æ•°æ®å¤„ç†æ–¹æ³• ä½¿ç”¨tokenizerå¤„ç† \n",
    "def tokenize_function(examples):\n",
    "    # ä½¿ç”¨tokenizerå¤„ç†exampleså­—å…¸ä¸­çš„\"text\"é”®å¯¹åº”çš„æ–‡æœ¬æ•°æ®\n",
    "    # padding=\"max_length\"è¡¨ç¤ºå°†æ‰€æœ‰åºåˆ—å¡«å……åˆ°æœ€å¤§é•¿åº¦ bert-base-cased æœ€å¤§ä¸º512\n",
    "    # truncation=Trueè¡¨ç¤ºå¦‚æœåºåˆ—é•¿åº¦è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œåˆ™è¿›è¡Œæˆªæ–­\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:26.850983Z",
     "iopub.status.busy": "2024-07-16T04:54:26.850754Z",
     "iopub.status.idle": "2024-07-16T04:54:26.862341Z",
     "shell.execute_reply": "2024-07-16T04:54:26.861401Z",
     "shell.execute_reply.started": "2024-07-16T04:54:26.850961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Great pizza! I normally travel all the way out to Coolidge for authentic New York style pizza. NYPD will not replace it, but it certainly will be a regular stop for me.</td>\n",
       "      <td>[101, 2038, 13473, 106, 146, 5156, 3201, 1155, 1103, 1236, 1149, 1106, 13297, 15091, 1111, 16047, 1203, 1365, 1947, 13473, 119, 5883, 15481, 1209, 1136, 4971, 1122, 117, 1133, 1122, 4664, 1209, 1129, 170, 2366, 1831, 1111, 1143, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
   "metadata": {},
   "source": [
    "### æ•°æ®æŠ½æ ·\n",
    "\n",
    "ä½¿ç”¨ 1000 ä¸ªæ•°æ®æ ·æœ¬ï¼Œåœ¨ BERT ä¸Šæ¼”ç¤ºå°è§„æ¨¡è®­ç»ƒï¼ˆåŸºäº Pytorch Trainerï¼‰\n",
    "\n",
    "`shuffle()`å‡½æ•°ä¼šéšæœºé‡æ–°æ’åˆ—åˆ—çš„å€¼ã€‚å¦‚æœæ‚¨å¸Œæœ›å¯¹ç”¨äºæ´—ç‰Œæ•°æ®é›†çš„ç®—æ³•æœ‰æ›´å¤šæ§åˆ¶ï¼Œå¯ä»¥åœ¨æ­¤å‡½æ•°ä¸­æŒ‡å®šgeneratorå‚æ•°æ¥ä½¿ç”¨ä¸åŒçš„numpy.random.Generatorã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17317d8-3c6a-467f-843d-87491f600db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:26.863472Z",
     "iopub.status.busy": "2024-07-16T04:54:26.863234Z",
     "iopub.status.idle": "2024-07-16T04:54:26.880820Z",
     "shell.execute_reply": "2024-07-16T04:54:26.880090Z",
     "shell.execute_reply.started": "2024-07-16T04:54:26.863449Z"
    }
   },
   "outputs": [],
   "source": [
    "#æŠ½å–å…¨é‡æ•°æ®é›†\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(650000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(50000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
   "metadata": {},
   "source": [
    "## å¾®è°ƒè®­ç»ƒé…ç½®\n",
    "\n",
    "### åŠ è½½ BERT æ¨¡å‹\n",
    "\n",
    "è­¦å‘Šé€šçŸ¥æˆ‘ä»¬æ­£åœ¨ä¸¢å¼ƒä¸€äº›æƒé‡ï¼ˆ`vocab_transform` å’Œ `vocab_layer_norm` å±‚ï¼‰ï¼Œå¹¶éšæœºåˆå§‹åŒ–å…¶ä»–ä¸€äº›æƒé‡ï¼ˆ`pre_classifier` å’Œ `classifier` å±‚ï¼‰ã€‚åœ¨å¾®è°ƒæ¨¡å‹æƒ…å†µä¸‹æ˜¯ç»å¯¹æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨åˆ é™¤ç”¨äºé¢„è®­ç»ƒæ¨¡å‹çš„æ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„å¤´éƒ¨ï¼Œå¹¶ç”¨ä¸€ä¸ªæ–°çš„å¤´éƒ¨æ›¿æ¢å®ƒï¼Œå¯¹äºè¿™ä¸ªæ–°å¤´éƒ¨ï¼Œæˆ‘ä»¬æ²¡æœ‰é¢„è®­ç»ƒçš„æƒé‡ï¼Œæ‰€ä»¥åº“ä¼šè­¦å‘Šæˆ‘ä»¬åœ¨ç”¨å®ƒè¿›è¡Œæ¨ç†ä¹‹å‰åº”è¯¥å¯¹è¿™ä¸ªæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè€Œè¿™æ­£æ˜¯æˆ‘ä»¬è¦åšçš„äº‹æƒ…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:26.881800Z",
     "iopub.status.busy": "2024-07-16T04:54:26.881594Z",
     "iopub.status.idle": "2024-07-16T04:54:28.085071Z",
     "shell.execute_reply": "2024-07-16T04:54:28.084469Z",
     "shell.execute_reply.started": "2024-07-16T04:54:26.881779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "#AutoModelForSequenceClassificationè‡ªåŠ¨åŠ è½½é€‚åˆäºåºåˆ—åˆ†ç±»ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åºåˆ—åˆ†ç±»ä»»åŠ¡é€šå¸¸åŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»ã€è§‚ç‚¹æŒ–æ˜ç­‰ï¼Œå…¶ä¸­è¾“å…¥æ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼Œè¾“å‡ºæ˜¯è¯¥åºåˆ—çš„ç±»åˆ«æ ‡ç­¾ã€‚\n",
    "#num_labels è¡¨ç¤ºåªåŠ è½½å‰5å±‚\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c907a70-5901-4ca3-9205-3d86228e2cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.086470Z",
     "iopub.status.busy": "2024-07-16T04:54:28.086071Z",
     "iopub.status.idle": "2024-07-16T04:54:28.093158Z",
     "shell.execute_reply": "2024-07-16T04:54:28.092419Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.086446Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"This is a test sentence.\",return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0e65ea-af90-40b8-ae5c-466aa682e102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.093977Z",
     "iopub.status.busy": "2024-07-16T04:54:28.093773Z",
     "iopub.status.idle": "2024-07-16T04:54:28.099975Z",
     "shell.execute_reply": "2024-07-16T04:54:28.099223Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.093956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1188, 1110,  170, 2774, 5650,  119,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6904d9b-1542-49fd-8fe8-cd3f52ced72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.100901Z",
     "iopub.status.busy": "2024-07-16T04:54:28.100702Z",
     "iopub.status.idle": "2024-07-16T04:54:28.119413Z",
     "shell.execute_reply": "2024-07-16T04:54:28.118622Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.100881Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs  = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5719d387-8897-489e-95e7-4889ff5b4d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.120329Z",
     "iopub.status.busy": "2024-07-16T04:54:28.120129Z",
     "iopub.status.idle": "2024-07-16T04:54:28.126373Z",
     "shell.execute_reply": "2024-07-16T04:54:28.125600Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.120309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.9853,  0.3214,  0.1799,  0.2356,  0.2071]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0dca6a1-fbea-432e-a691-69b5abfedc98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.127133Z",
     "iopub.status.busy": "2024-07-16T04:54:28.126939Z",
     "iopub.status.idle": "2024-07-16T04:54:28.131703Z",
     "shell.execute_reply": "2024-07-16T04:54:28.130563Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.127113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44014df-b52c-4c72-9e9f-54424725a473",
   "metadata": {},
   "source": [
    "### è®­ç»ƒè¶…å‚æ•°ï¼ˆTrainingArgumentsï¼‰\n",
    "\n",
    "å®Œæ•´é…ç½®å‚æ•°ä¸é»˜è®¤å€¼ï¼šhttps://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "æºä»£ç å®šä¹‰ï¼šhttps://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
    "\n",
    "**æœ€é‡è¦é…ç½®ï¼šæ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„(output_dir)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.132464Z",
     "iopub.status.busy": "2024-07-16T04:54:28.132267Z",
     "iopub.status.idle": "2024-07-16T04:54:28.209489Z",
     "shell.execute_reply": "2024-07-16T04:54:28.208075Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.132443Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# è®¾ç½®æ¨¡å‹ä¿å­˜çš„ç›®å½•\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp-0716\"\n",
    "\n",
    "# åˆå§‹åŒ–TrainingArgumentsç±»ï¼Œç”¨äºæŒ‡å®šè®­ç»ƒè¿‡ç¨‹çš„å‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,  # è®¾ç½®æ¨¡å‹çš„è¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œæ—¥å¿—æ–‡ä»¶\n",
    "    per_device_train_batch_size=32,  # è®¾ç½®æ¯ä¸ªGPU/CPUåœ¨è®­ç»ƒæ—¶ä½¿ç”¨çš„æ‰¹é‡å¤§å°\n",
    "    num_train_epochs=5,  # è®¾ç½®è®­ç»ƒçš„æ€»è½®æ•°\n",
    "    logging_steps=100  # è®¾ç½®æ‰“å°æ—¥å¿—çš„æ­¥é•¿ï¼Œå³æ¯100æ­¥æ‰“å°ä¸€æ¬¡æ—¥å¿—ä¿¡æ¯ï¼Œé»˜è®¤å€¼ä¸º500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.210654Z",
     "iopub.status.busy": "2024-07-16T04:54:28.210362Z",
     "iopub.status.idle": "2024-07-16T04:54:28.216813Z",
     "shell.execute_reply": "2024-07-16T04:54:28.215598Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.210625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp-0716/runs/Jul16_12-54-28_autodl-container-6dda4b9e00-7a2a7cc7,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp-0716,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp-0716,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# å®Œæ•´çš„è¶…å‚æ•°é…ç½®\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
   "metadata": {},
   "source": [
    "### è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡è¯„ä¼°ï¼ˆEvaluate)\n",
    "\n",
    "**[Hugging Face Evaluate åº“](https://huggingface.co/docs/evaluate/index)** æ”¯æŒä½¿ç”¨ä¸€è¡Œä»£ç ï¼Œè·å¾—æ•°åç§ä¸åŒé¢†åŸŸï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€å¼ºåŒ–å­¦ä¹ ç­‰ï¼‰çš„è¯„ä¼°æ–¹æ³•ã€‚ å½“å‰æ”¯æŒ **å®Œæ•´è¯„ä¼°æŒ‡æ ‡ï¼šhttps://huggingface.co/evaluate-metric**\n",
    "\n",
    "è®­ç»ƒå™¨ï¼ˆTrainerï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ä¼šè‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å‘è®­ç»ƒå™¨ä¼ é€’ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å’ŒæŠ¥å‘ŠæŒ‡æ ‡ã€‚ \n",
    "\n",
    "Evaluateåº“æä¾›äº†ä¸€ä¸ªç®€å•çš„å‡†ç¡®ç‡å‡½æ•°ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`evaluate.load`å‡½æ•°åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:28.217980Z",
     "iopub.status.busy": "2024-07-16T04:54:28.217724Z",
     "iopub.status.idle": "2024-07-16T04:54:31.755904Z",
     "shell.execute_reply": "2024-07-16T04:54:31.754956Z",
     "shell.execute_reply.started": "2024-07-16T04:54:28.217955Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
   "metadata": {},
   "source": [
    "\n",
    "æ¥ç€ï¼Œè°ƒç”¨ `compute` å‡½æ•°æ¥è®¡ç®—é¢„æµ‹çš„å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "åœ¨å°†é¢„æµ‹ä¼ é€’ç»™ compute å‡½æ•°ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°† logits è½¬æ¢ä¸ºé¢„æµ‹å€¼ï¼ˆ**æ‰€æœ‰Transformers æ¨¡å‹éƒ½è¿”å› logits**ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:31.757465Z",
     "iopub.status.busy": "2024-07-16T04:54:31.756896Z",
     "iopub.status.idle": "2024-07-16T04:54:31.761234Z",
     "shell.execute_reply": "2024-07-16T04:54:31.760574Z",
     "shell.execute_reply.started": "2024-07-16T04:54:31.757440Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1",
   "metadata": {},
   "source": [
    "#### è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡ç›‘æ§\n",
    "\n",
    "é€šå¸¸ï¼Œä¸ºäº†ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä¼°æŒ‡æ ‡å˜åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨`TrainingArguments`æŒ‡å®š`evaluation_strategy`å‚æ•°ï¼Œä»¥ä¾¿åœ¨ epoch ç»“æŸæ—¶æŠ¥å‘Šè¯„ä¼°æŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:31.763931Z",
     "iopub.status.busy": "2024-07-16T04:54:31.763714Z",
     "iopub.status.idle": "2024-07-16T04:54:31.816941Z",
     "shell.execute_reply": "2024-07-16T04:54:31.815966Z",
     "shell.execute_reply.started": "2024-07-16T04:54:31.763909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# åˆå§‹åŒ–TrainingArgumentså®ä¾‹ï¼Œè¿™æ˜¯ç”¨äºé…ç½®è®­ç»ƒè¿‡ç¨‹çš„å‚æ•°é›†åˆ\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,  # è¾“å‡ºç›®å½•ï¼šæŒ‡å®šè®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ¨¡å‹å’Œæ—¥å¿—æ–‡ä»¶å°†è¢«ä¿å­˜åœ¨å“ªä¸ªç›®å½•ä¸‹\n",
    "    evaluation_strategy=\"epoch\",  # è¯„ä¼°ç­–ç•¥ï¼šæŒ‡å®šæ¨¡å‹è¯„ä¼°çš„æ—¶æœºã€‚è¿™é‡Œè®¾ç½®ä¸º\"epoch\"ï¼Œè¡¨ç¤ºæ¯ä¸ªè®­ç»ƒè½®ï¼ˆepochï¼‰ç»“æŸåè¿›è¡Œä¸€æ¬¡è¯„ä¼°\n",
    "    per_device_train_batch_size=32,  # æ‰¹é‡å¤§å°ï¼šæ¯ä¸ªè®­ç»ƒè®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰ä¸Šä¸€æ¬¡å¤„ç†çš„æ ·æœ¬æ•°é‡ã€‚æ‰¹é‡å¤§å°å½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œå†…å­˜ä½¿ç”¨\n",
    "    num_train_epochs=3,  # è®­ç»ƒè½®æ•°ï¼šæŒ‡å®šæ¨¡å‹å°†åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå®Œæ•´è®­ç»ƒçš„æ¬¡æ•°ã€‚æ¯ä¸ªè½®æ•°æ¨¡å‹å°†çœ‹åˆ°æ•´ä¸ªæ•°æ®é›†ä¸€æ¬¡\n",
    "    logging_steps=100,  # æ—¥å¿—æ­¥æ•°ï¼šæŒ‡å®šè®­ç»ƒè¿‡ç¨‹ä¸­æ¯å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡æ—¥å¿—ä¿¡æ¯ã€‚è¿™é‡Œè®¾ç½®ä¸º30ï¼Œæ„å‘³ç€æ¯30ä¸ªè®­ç»ƒæ­¥éª¤ä¼šæ‰“å°ä¸€æ¬¡æ—¥å¿—\n",
    "    save_steps=5000, #è®¾ç½®æ¯1000ä¸ªè®­ç»ƒæ­¥éª¤ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹\n",
    "    save_total_limit=10,#é™åˆ¶ä¿å­˜çš„æ£€æŸ¥ç‚¹æ•°é‡\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
   "metadata": {},
   "source": [
    "## å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "### å®ä¾‹åŒ–è®­ç»ƒå™¨ï¼ˆTrainerï¼‰\n",
    "\n",
    "`kernel version` ç‰ˆæœ¬é—®é¢˜ï¼šæš‚ä¸å½±å“æœ¬ç¤ºä¾‹ä»£ç è¿è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:31.818893Z",
     "iopub.status.busy": "2024-07-16T04:54:31.818214Z",
     "iopub.status.idle": "2024-07-16T04:54:32.159065Z",
     "shell.execute_reply": "2024-07-16T04:54:32.158387Z",
     "shell.execute_reply.started": "2024-07-16T04:54:31.818852Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,#æ¨¡å‹\n",
    "    args=training_args,#è®­ç»ƒå‚æ•°\n",
    "    train_dataset=small_train_dataset,#è®­ç»ƒæ•°æ®é›†\n",
    "    eval_dataset=small_eval_dataset,#éªŒè¯æ•°æ®é›†\n",
    "    compute_metrics=compute_metrics,#éªŒè¯æ–¹æ³•\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ nvidia-smi æŸ¥çœ‹ GPU ä½¿ç”¨\n",
    "\n",
    "ä¸ºäº†å®æ—¶æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µï¼Œå¯ä»¥ä½¿ç”¨ `watch` æŒ‡ä»¤å®ç°è½®è¯¢ï¼š`watch -n 1 nvidia-smi`:\n",
    "\n",
    "```shell\n",
    "Every 1.0s: nvidia-smi                                                   Wed Dec 20 14:37:41 2023\n",
    "\n",
    "Wed Dec 20 14:37:41 2023\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  Tesla T4                       Off | 00000000:00:0D.0 Off |                    0 |\n",
    "| N/A   64C    P0              69W /  70W |   6665MiB / 15360MiB |     98%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0   N/A  N/A     18395      C   /root/miniconda3/bin/python                6660MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accfe921-471d-481a-96da-c491cdebad0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:54:32.160284Z",
     "iopub.status.busy": "2024-07-16T04:54:32.159912Z",
     "iopub.status.idle": "2024-07-16T09:13:57.811040Z",
     "shell.execute_reply": "2024-07-16T09:13:57.810103Z",
     "shell.execute_reply.started": "2024-07-16T04:54:32.160262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43407' max='60939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43407/60939 4:19:24 < 1:44:46, 2.79 it/s, Epoch 2.14/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.610300</td>\n",
       "      <td>1.609557</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.609200</td>\n",
       "      <td>1.609450</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(model_dir)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d581099-37a4-4470-b051-1ada38554089",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.811840Z",
     "iopub.status.idle": "2024-07-16T09:13:57.812111Z",
     "shell.execute_reply": "2024-07-16T09:13:57.811993Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.811980Z"
    }
   },
   "outputs": [],
   "source": [
    "#åŠ è½½æµ‹è¯•é›†\n",
    "# small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.813137Z",
     "iopub.status.idle": "2024-07-16T09:13:57.813381Z",
     "shell.execute_reply": "2024-07-16T09:13:57.813274Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.813263Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
   "metadata": {},
   "source": [
    "### ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒçŠ¶æ€\n",
    "\n",
    "- ä½¿ç”¨ `trainer.save_model` æ–¹æ³•ä¿å­˜æ¨¡å‹ï¼Œåç»­å¯ä»¥é€šè¿‡ from_pretrained() æ–¹æ³•é‡æ–°åŠ è½½\n",
    "- ä½¿ç”¨ `trainer.save_state` æ–¹æ³•ä¿å­˜è®­ç»ƒçŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.814011Z",
     "iopub.status.idle": "2024-07-16T09:13:57.814225Z",
     "shell.execute_reply": "2024-07-16T09:13:57.814126Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.814115Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e30510-0536-49d4-8e1b-43fc25272bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.814864Z",
     "iopub.status.idle": "2024-07-16T09:13:57.815111Z",
     "shell.execute_reply": "2024-07-16T09:13:57.815002Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.814990Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9441ad-f65a-42b7-9016-4809c78285e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.820402Z",
     "iopub.status.idle": "2024-07-16T09:13:57.820832Z",
     "shell.execute_reply": "2024-07-16T09:13:57.820690Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.820675Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.model.save_pretrained(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84da9f9-26ab-4bd3-b6a2-9330d9ae4688",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.821621Z",
     "iopub.status.idle": "2024-07-16T09:13:57.821863Z",
     "shell.execute_reply": "2024-07-16T09:13:57.821757Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.821745Z"
    }
   },
   "outputs": [],
   "source": [
    "#åŠ è½½è®­ç»ƒå®Œçš„æ¨¡å‹\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# æŒ‡å®šæ¨¡å‹ä¿å­˜çš„è·¯å¾„\n",
    "\n",
    "\n",
    "# åŠ è½½tokenizerå’Œæ¨¡å‹\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "model.eval()\n",
    "\n",
    "# ç°åœ¨æ¨¡å‹å·²ç»åŠ è½½ï¼Œå¯ä»¥ç”¨äºæ¨ç†æˆ–è¿›ä¸€æ­¥çš„å¤„ç†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ff6b1-ef85-458f-8cbb-e2a004617f4e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-16T09:13:57.822541Z",
     "iopub.status.idle": "2024-07-16T09:13:57.822766Z",
     "shell.execute_reply": "2024-07-16T09:13:57.822665Z",
     "shell.execute_reply.started": "2024-07-16T09:13:57.822653Z"
    }
   },
   "outputs": [],
   "source": [
    "# è¾“å…¥æ–‡æœ¬\n",
    "text = \"Here is some text to classify.\"\n",
    "\n",
    "# ä½¿ç”¨tokenizerå¤„ç†æ–‡æœ¬\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "\n",
    "# è·å–é¢„æµ‹ç»“æœ\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61828934-01da-4fc3-9e75-8d754c25dfbc",
   "metadata": {},
   "source": [
    "## Homework: ä½¿ç”¨å®Œæ•´çš„ YelpReviewFull æ•°æ®é›†è®­ç»ƒï¼Œçœ‹ Acc æœ€é«˜èƒ½åˆ°å¤šå°‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2580a-7a5a-46ae-a28b-b41e9e838eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
